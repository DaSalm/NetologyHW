{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "language_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaSalm/NetologyHW/blob/master/language_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cIyHs0z2W69",
        "colab_type": "text"
      },
      "source": [
        "# Language modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctnh7erD2W7A",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Обучим две различные символьные модели для генерации динозавров:\n",
        "* модель на символьных биграмах\n",
        "* ***RNN***-модель.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icDKK39w2W7E",
        "colab_type": "text"
      },
      "source": [
        "## Bigram model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLqGOla02W7I",
        "colab_type": "code",
        "outputId": "0d33b809-f966-4312-b164-ec001dc028c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/artemovae/NLP-seminar-LM/master/dinos.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-25 16:12:03--  https://raw.githubusercontent.com/artemovae/NLP-seminar-LM/master/dinos.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19909 (19K) [text/plain]\n",
            "Saving to: ‘dinos.txt’\n",
            "\n",
            "\rdinos.txt             0%[                    ]       0  --.-KB/s               \rdinos.txt           100%[===================>]  19.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-12-25 16:12:03 (69.3 MB/s) - ‘dinos.txt’ saved [19909/19909]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyjJEQQKMDoJ",
        "colab_type": "code",
        "outputId": "d7ede4e8-b51c-4885-85a9-c72d032fb082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cat dinos.txt | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbCaai3s2W7P",
        "colab_type": "code",
        "outputId": "0a0e7fab-63f9-46d0-f27f-b656bda6561b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!cat dinos.txt | head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aachenosaurus\n",
            "Aardonyx\n",
            "Abdallahsaurus\n",
            "Abelisaurus\n",
            "Abrictosaurus\n",
            "Abrosaurus\n",
            "Abydosaurus\n",
            "Acanthopholis\n",
            "Achelousaurus\n",
            "Acheroraptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ScelDkNdJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in range(10):\n",
        "  a.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLbaIg_9NqCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = [i + 2 for i in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VygFhFU7NvBY",
        "colab_type": "code",
        "outputId": "c5e6626c-dd39-404f-8305-9776549a208d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53omaXQx2W7W",
        "colab_type": "code",
        "outputId": "0182df06-4c60-447a-8777-2e98288184ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "names = ['<' + name.strip().lower() + '>' for name in open('dinos.txt').readlines()]\n",
        "print(names[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<aachenosaurus>', '<aardonyx>', '<abdallahsaurus>', '<abelisaurus>', '<abrictosaurus>', '<abrosaurus>', '<abydosaurus>', '<acanthopholis>', '<achelousaurus>', '<acheroraptor>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ju3s-UA2W7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huzFXq1S2W7g",
        "colab_type": "text"
      },
      "source": [
        "Вычислим частоту каждого символа в корпусе имен динозавров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3YmhuB7OLwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = [char for name in names for char in name]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_aMqsrF2W7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq = nltk.FreqDist(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQHW1Ycw2W7t",
        "colab_type": "code",
        "outputId": "a8816d7e-46cb-4026-92ca-3f70f73317bd",
        "colab": {}
      },
      "source": [
        "print(list(freq.keys()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['h', 'p', 'i', 'u', 'q', '<', 'b', 'a', 'r', 'x', 'g', 'e', 'o', 'l', 'c', 'j', 'z', 's', 'd', 'f', 'y', 'm', 'v', 'n', 'w', '>', 'k', 't']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNj82xL2W7w",
        "colab_type": "code",
        "outputId": "64fc403d-021f-42a4-ffe5-698e0088d737",
        "colab": {}
      },
      "source": [
        "freq.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2487),\n",
              " ('s', 2285),\n",
              " ('u', 2123),\n",
              " ('o', 1710),\n",
              " ('r', 1704),\n",
              " ('<', 1536),\n",
              " ('>', 1536),\n",
              " ('n', 1081),\n",
              " ('i', 944),\n",
              " ('e', 913)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUC2JNwp2W72",
        "colab_type": "text"
      },
      "source": [
        "Define a function to estimate probabilty of character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAV_ygtc2W74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = sum([freq[char] for char in freq])\n",
        "\n",
        "def unigram_prob(char):\n",
        "    return freq[char] / l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hafHBb_sPYMq",
        "colab_type": "code",
        "outputId": "7f22e2b2-1ba9-4446-b126-c9ab22eb3934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "unigram_prob('a')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11596568124591998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFVB337N2W8A",
        "colab_type": "code",
        "outputId": "87219690-3164-4a9b-e370-c0431515b793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('p(a) = %1.4f' %unigram_prob('a'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(a) = 0.1160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAqP-2Ga2W8H",
        "colab_type": "text"
      },
      "source": [
        "Вычислим условную вероятность каждого символа в зависимости от того, какой символ стоял на предыдущей позиции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Gvm3-cPhO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = nltk.bigrams(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_0_CPd2W8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FhBVamN2W8P",
        "colab_type": "code",
        "outputId": "2cc112cf-b641-4425-b609-9544c8135632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "cfreq['a']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'>': 138,\n",
              "          'a': 11,\n",
              "          'b': 24,\n",
              "          'c': 100,\n",
              "          'd': 36,\n",
              "          'e': 42,\n",
              "          'f': 6,\n",
              "          'g': 40,\n",
              "          'h': 17,\n",
              "          'i': 23,\n",
              "          'j': 5,\n",
              "          'k': 20,\n",
              "          'l': 138,\n",
              "          'm': 68,\n",
              "          'n': 347,\n",
              "          'o': 22,\n",
              "          'p': 89,\n",
              "          'q': 3,\n",
              "          'r': 124,\n",
              "          's': 171,\n",
              "          't': 204,\n",
              "          'u': 791,\n",
              "          'v': 30,\n",
              "          'w': 6,\n",
              "          'x': 12,\n",
              "          'y': 12,\n",
              "          'z': 8})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDvwaROA2W8U",
        "colab_type": "text"
      },
      "source": [
        "Оценим условные вероятности с помощью MLE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "571c4Mc82W8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLM-a_kG2W8e",
        "colab_type": "code",
        "outputId": "ae3ba281-9bd1-4934-e5fa-1430a2622d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('p(a a) = %1.4f' %cprob['a'].prob('a'))\n",
        "print('p(a b) = %1.4f' %cprob['a'].prob('b'))\n",
        "print('p(a u) = %1.4f' %cprob['a'].prob('u'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(a a) = 0.0044\n",
            "p(a b) = 0.0097\n",
            "p(a u) = 0.3181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOT_Y7Dv2W8i",
        "colab_type": "code",
        "outputId": "51f304db-1b5a-4a42-f601-cbb3f9321a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cprob['a'].generate()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPPmGYnjQiOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INuJG66hQkHU",
        "colab_type": "code",
        "outputId": "f2c6ffc6-bc48-44ed-9f43-73393d1cfae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.random.choice([1, 3, 43, 4, 4, 4, 4], p=[0.8, 0.05, 0.05, 0.025, 0.025, 0.025, 0.025])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkG0tWfw2W8o",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1.\n",
        "\n",
        "1) Напишите функцию, которая генерирует имя динозавра **фиксированной** длины. Используйте '<' как начальный символ.\n",
        "\n",
        "2) Напишите функцию, которая генерирует имя динозавра любой дины."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syCACFiX2W8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_n_chars(cprob, n):\n",
        "  name = '<'\n",
        "  for i in range(n):\n",
        "    name += cprob[name[-1]].generate()\n",
        "\n",
        "    if name[-1] == '>':\n",
        "      break\n",
        "\n",
        "  if name[-1] != '>':\n",
        "    name += '>'\n",
        "  return name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybl5nwvNSYFc",
        "colab_type": "code",
        "outputId": "0a972d87-8b17-400a-bf18-1f28119d395a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "generate_n_chars(cprob, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<crurustato>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyUlzjM2W8z",
        "colab_type": "text"
      },
      "source": [
        "## Реккурентные нейронные сети (RNN)\n",
        "\n",
        "Исходная последовательность:\n",
        "\n",
        "$x_{1:n} = x_1, x_2, \\ldots, x_n$, $x_i \\in \\mathbb{R}^{d_{in}}$\n",
        "\n",
        "Для каждого входного значения $x_{1:i}$ получаем на выходе $y_i$:\n",
        "\n",
        "$y_i = RNN(x_{1:i})$, $y_i \\in \\mathbb{R}^{d_{out}}$\n",
        "\n",
        "Для всей последовательности $x_{1:n}$:\n",
        "\n",
        "$y_{1:n} = RNN^{*}(x_{1:n})$, $y_i \\in \\mathbb{R}^{d_{out}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XasEOhf22W80",
        "colab_type": "text"
      },
      "source": [
        "$R$ - рекурсивная функция активации, зависящая от двух параметров: $x_i$ и $s_{i-1}$ (вектор предыдущего состояния)\n",
        "\n",
        "$RNN^{*}(x_{1:n}, s_0) = y_{1:n}$\n",
        "\n",
        "$y_i = O(s_i) = g(W^{out}[s_{i} ,x_i] +b)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i) = g(W^{hid}[s_{i-1} ,x_i] +b)$  -- конкатенация $[s_{i-1}, x]$\n",
        "\n",
        "$x_i \\in \\mathbb{R}^{d_{in}}$, $y_i \\in \\mathbb{R}^{ d_{out}}$, $s_i \\in \\mathbb{R}^{d_{hid}}$\n",
        "\n",
        "$W^{hid} \\in \\mathbb{R}^{(d_{in}+d_{out}) \\times d_{hid}}$, $W^{out} \\in \\mathbb{R}^{d_{hid} \\times d_{out}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF25X2-r2W83",
        "colab_type": "text"
      },
      "source": [
        "Построим языковую модель на основе RNN с помощью pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqYwbT6_2W8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pdb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "torch.set_printoptions(linewidth=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZkbUpfD2W9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "hidden_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQyNMXYQTJPi",
        "colab_type": "code",
        "outputId": "d55324c6-e88c-4452-e9f0-239be41bb091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nBHODnI2W9O",
        "colab_type": "text"
      },
      "source": [
        "Подготовим данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "kErAELLg2W9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DinosDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        with open('dinos.txt') as f:\n",
        "            content = f.read().lower()\n",
        "            self.vocab = sorted(set(content)) + ['<', '>']\n",
        "            self.vocab_size = len(self.vocab)\n",
        "            self.lines = content.splitlines()\n",
        "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
        "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        line = self.lines[index]\n",
        "        #teacher forcing\n",
        "        x_str = '<' + line \n",
        "        y_str = line + '>' \n",
        "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
        "        y = torch.empty(len(x_str), dtype=torch.long)\n",
        "        for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)):\n",
        "            x[i][self.ch_to_idx[x_ch]] = 1\n",
        "            y[i] = self.ch_to_idx[y_ch]\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOThKZfLYBPU",
        "colab_type": "code",
        "outputId": "44131547-61b6-4822-ff76-1911fc660a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(zip('<dino', 'dino>'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<', 'd'), ('d', 'i'), ('i', 'n'), ('n', 'o'), ('o', '>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyd57bI62W9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_ds = DinosDataset()\n",
        "trn_dl = DataLoader(trn_ds, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDGovG9uWV1A",
        "colab_type": "code",
        "outputId": "da018f65-b555-43ea-d519-a2a8e98aeec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trn_ds.lines[5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abrosaurus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ-DwzbA2W9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = trn_ds[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54S20GFZcwT",
        "colab_type": "code",
        "outputId": "41c44837-16bd-4e6a-bd66-334011185120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2, 18, 15, 19,  1, 21, 18, 21, 19, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBjdwRdA2W9h",
        "colab_type": "code",
        "outputId": "8dfb52e6-d46f-4e60-d65b-a9d9d080bbde",
        "colab": {}
      },
      "source": [
        "print(trn_ds.idx_to_ch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '<', 28: '>'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyOMbom22W9k",
        "colab_type": "code",
        "outputId": "4f62455e-5326-4a73-dcd8-0a7199bdbab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trn_ds.vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_RPozaCI2W9s",
        "colab_type": "code",
        "outputId": "a7e6752b-875a-428c-9f5f-52862a1c5390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrvBVxSJ2W9y",
        "colab_type": "code",
        "outputId": "9e994520-211f-44e6-83c4-7aaf6e8d2ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al77yNu32W91",
        "colab_type": "code",
        "outputId": "21a0a0ad-103a-4d7f-95ef-662f22c1a47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[trn_ds.idx_to_ch[i.item()] for i in y]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'r', 'o', 's', 'a', 'u', 'r', 'u', 's', '>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2qnz4zJ2W94",
        "colab_type": "text"
      },
      "source": [
        "Опишем модель, функцию потерь и алгоритм оптимизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "EkZts5sS2W97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, h_prev, x):\n",
        "        combined = torch.cat([h_prev, x], dim = 1) # concatenate x and h\n",
        "        h = torch.tanh(self.dropout(self.i2h(combined)))\n",
        "        y = self.i2o(h)\n",
        "        return h, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00CYQEP2W-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdIRV3wh2W-C",
        "colab_type": "text"
      },
      "source": [
        "![rnn](images/dinos3.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "I-eL2J-62W-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(model):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>'] # индекс конечного символа\n",
        "    with torch.no_grad():\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device) # первый вектор скрытого состояния\n",
        "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<'] # индекс начального символа\n",
        "        x[0, start_char_idx] = 1 # one-hot вектор для начального символа\n",
        "\n",
        "        indices = [start_char_idx]      \n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "pBSVq-mT2W-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_sample(sample_idxs):\n",
        "    print(''.join([trn_ds.idx_to_ch[x] for x in sample_idxs]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iZf2BAn2W-L",
        "colab_type": "text"
      },
      "source": [
        "Обучим получившуюся модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNerAiBfm8i",
        "colab_type": "code",
        "outputId": "3e0989b2-22f2-441b-ad9c-e900a8d34ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.size()[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "VA6yHuJ72W-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_epoch(model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    for line_num, (x, y) in enumerate(trn_dl):\n",
        "        loss = 0\n",
        "        \n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h_prev, y_pred = model(h_prev, x[:, i])\n",
        "            loss += loss_fn(y_pred, y[:, i])\n",
        "            \n",
        "        if (line_num + 1) % 200 == 0:\n",
        "            print('loss', loss.item() / y.size()[0])\n",
        "            print_sample(sample(model))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "ZlzFfO4A2W-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
        "    for e in range(1, epochs+1):\n",
        "        print('Epoch:{}'.format(e))\n",
        "        train_one_epoch(model, loss_fn, optimizer)\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WVExA_rP2W-a",
        "colab_type": "code",
        "outputId": "23c0c2b7-809a-463b-cf6f-4d2b8b4a9c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model, loss_fn, optimizer, epochs = 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1\n",
            "loss 36.22065734863281\n",
            "<sdg>\n",
            "loss 31.024066925048828\n",
            "<lnrus>\n",
            "loss 30.07791519165039\n",
            "<sourasaerus>\n",
            "loss 24.26682472229004\n",
            "<girusharus>\n",
            "loss 22.46570587158203\n",
            "<atjaskurui>\n",
            "loss 28.10103988647461\n",
            "<ynucssnurus>\n",
            "loss 25.450807571411133\n",
            "<zulotobhsaoudroynrusaurxs>\n",
            "\n",
            "Epoch:2\n",
            "loss 18.97470474243164\n",
            "<auansosausus>\n",
            "loss 19.69462013244629\n",
            "<sintunortairai>\n",
            "loss 16.424253463745117\n",
            "<amltakhuhus>\n",
            "loss 36.60989761352539\n",
            "<gabscaurus>\n",
            "loss 31.39891242980957\n",
            "<topnusaurus>\n",
            "loss 22.008193969726562\n",
            "<tbjhddteus>\n",
            "loss 11.527524948120117\n",
            "<airpaurus>\n",
            "\n",
            "Epoch:3\n",
            "loss 21.711658477783203\n",
            "<auajtaurus>\n",
            "loss 17.585601806640625\n",
            "<lanrnviurus>\n",
            "loss 17.016849517822266\n",
            "<kbbpudaurus>\n",
            "loss 19.65509033203125\n",
            "<laidonalros>\n",
            "loss 16.544395446777344\n",
            "<pucrsdurus>\n",
            "loss 13.841693878173828\n",
            "<yuirtsamsauras>\n",
            "loss 34.29077911376953\n",
            "<talsua>\n",
            "\n",
            "Epoch:4\n",
            "loss 19.199398040771484\n",
            "<cplras>\n",
            "loss 24.156190872192383\n",
            "<juptasaurus>\n",
            "loss 27.526050567626953\n",
            "<iysosiurus>\n",
            "loss 16.011913299560547\n",
            "<etasisam>\n",
            "loss 19.2605037689209\n",
            "<lbiesaurus>\n",
            "loss 31.98565101623535\n",
            "<xrucrrotops>\n",
            "loss 17.91503143310547\n",
            "<zsnostcisaurus>\n",
            "\n",
            "Epoch:5\n",
            "loss 21.461013793945312\n",
            "<tccsnaurus>\n",
            "loss 22.281780242919922\n",
            "<atbhtaurus>\n",
            "loss 19.951984405517578\n",
            "<meronuurus>\n",
            "loss 29.64643096923828\n",
            "<anicisaurus>\n",
            "loss 25.180843353271484\n",
            "<sibogopaurus>\n",
            "loss 22.366294860839844\n",
            "<oreprungsaurus>\n",
            "loss 20.555980682373047\n",
            "<sranicaurus>\n",
            "\n",
            "Epoch:6\n",
            "loss 26.92814826965332\n",
            "<agrua>\n",
            "loss 24.502286911010742\n",
            "<dtloasaurus>\n",
            "loss 24.622102737426758\n",
            "<susherosturus>\n",
            "loss 28.348445892333984\n",
            "<aniansasaurus>\n",
            "loss 30.083019256591797\n",
            "<aoatauous>\n",
            "loss 14.779732704162598\n",
            "<wrueosaurus>\n",
            "loss 25.45125961303711\n",
            "<yuhosafrus>\n",
            "\n",
            "Epoch:7\n",
            "loss 30.0972900390625\n",
            "<sauitaeouatr>\n",
            "loss 25.41583251953125\n",
            "<hecrcsor>\n",
            "loss 20.937236785888672\n",
            "<busopaurus>\n",
            "loss 16.608322143554688\n",
            "<krssaaurus>\n",
            "loss 30.491727828979492\n",
            "<saucasanrus>\n",
            "loss 16.80786895751953\n",
            "<garalsotuus>\n",
            "loss 20.04431915283203\n",
            "<leoplsrtorsats>\n",
            "\n",
            "Epoch:8\n",
            "loss 30.756702423095703\n",
            "<fraiisaeaurus>\n",
            "loss 23.33188247680664\n",
            "<hhducgtaurus>\n",
            "loss 30.754085540771484\n",
            "<maurotaurus>\n",
            "loss 19.123201370239258\n",
            "<kgcrudaurus>\n",
            "loss 23.758142471313477\n",
            "<maresaurus>\n",
            "loss 15.53429126739502\n",
            "<xpucturus>\n",
            "loss 25.784772872924805\n",
            "<rnysnauris>\n",
            "\n",
            "Epoch:9\n",
            "loss 28.157394409179688\n",
            "<alpandtcaurus>\n",
            "loss 29.776243209838867\n",
            "<smgasaotaurus>\n",
            "loss 23.048885345458984\n",
            "<mauroviurus>\n",
            "loss 17.526424407958984\n",
            "<jnahoconter>\n",
            "loss 28.39461898803711\n",
            "<lapgronaurus>\n",
            "loss 19.44548797607422\n",
            "<ugtoooaurus>\n",
            "loss 24.67462158203125\n",
            "<krouaaurus>\n",
            "\n",
            "Epoch:10\n",
            "loss 9.645365715026855\n",
            "<rnsaboodaurus>\n",
            "loss 27.296571731567383\n",
            "<tantote>\n",
            "loss 10.869500160217285\n",
            "<stlesaurus>\n",
            "loss 24.857759475708008\n",
            "<subrlchoera>\n",
            "loss 12.118919372558594\n",
            "<aauraperapeor>\n",
            "loss 20.170166015625\n",
            "<wqthrsoonaurus>\n",
            "loss 52.31279373168945\n",
            "<pttanicaurus>\n",
            "\n",
            "Epoch:11\n",
            "loss 23.302331924438477\n",
            "<aiooaaurus>\n",
            "loss 21.02988052368164\n",
            "<tcctosaurus>\n",
            "loss 20.32721519470215\n",
            "<rolwtgpuses>\n",
            "loss 16.906993865966797\n",
            "<betatotaurur>\n",
            "loss 18.46502685546875\n",
            "<cuehasaurus>\n",
            "loss 21.432640075683594\n",
            "<susihsaurus>\n",
            "loss 12.614297866821289\n",
            "<suanocaurus>\n",
            "\n",
            "Epoch:12\n",
            "loss 20.11318016052246\n",
            "<agohasaurus>\n",
            "loss 22.6231689453125\n",
            "<anvpsaurus>\n",
            "loss 15.566228866577148\n",
            "<ssnysaurus>\n",
            "loss 16.9682674407959\n",
            "<lalrasaurus>\n",
            "loss 12.238584518432617\n",
            "<ahehinaurus>\n",
            "loss 16.012378692626953\n",
            "<tgttsaurus>\n",
            "loss 13.020724296569824\n",
            "<tpotrcaurus>\n",
            "\n",
            "Epoch:13\n",
            "loss 34.26446533203125\n",
            "<saudhs>\n",
            "loss 16.335927963256836\n",
            "<aigrupaurus>\n",
            "loss 15.947286605834961\n",
            "<tgtssaurus>\n",
            "loss 39.744178771972656\n",
            "<thurtchodaurus>\n",
            "loss 19.064292907714844\n",
            "<agthanaurus>\n",
            "loss 28.3123722076416\n",
            "<ahynubrsssaurus>\n",
            "loss 22.70153045654297\n",
            "<lortbisaurus>\n",
            "\n",
            "Epoch:14\n",
            "loss 24.808441162109375\n",
            "<taarocaurus>\n",
            "loss 28.313133239746094\n",
            "<santosaurus>\n",
            "loss 15.617193222045898\n",
            "<rtm>\n",
            "loss 20.996429443359375\n",
            "<snnrsaosaurus>\n",
            "loss 27.4752254486084\n",
            "<tbcosaurus>\n",
            "loss 32.49907684326172\n",
            "<argevourus>\n",
            "loss 27.896648406982422\n",
            "<llosguaurus>\n",
            "\n",
            "Epoch:15\n",
            "loss 15.611154556274414\n",
            "<khcrus>\n",
            "loss 23.54638671875\n",
            "<ftaesanrus>\n",
            "loss 27.574403762817383\n",
            "<gctanvotaurus>\n",
            "loss 16.760957717895508\n",
            "<sinyslsaurus>\n",
            "loss 27.494281768798828\n",
            "<etasitaurus>\n",
            "loss 10.133454322814941\n",
            "<cropaodhxtor>\n",
            "loss 18.491111755371094\n",
            "<trgesoovaurus>\n",
            "\n",
            "Epoch:16\n",
            "loss 32.21299362182617\n",
            "<ipcosaurus>\n",
            "loss 28.94573211669922\n",
            "<siarisaurus>\n",
            "loss 10.52149772644043\n",
            "<xrudturus>\n",
            "loss 32.323333740234375\n",
            "<rhvrlsaurus>\n",
            "loss 24.07423973083496\n",
            "<ftatisaurur>\n",
            "loss 31.53069496154785\n",
            "<csghataurus>\n",
            "loss 28.219654083251953\n",
            "<sutonaurus>\n",
            "\n",
            "Epoch:17\n",
            "loss 32.27904510498047\n",
            "<probipaurus>\n",
            "loss 31.88921546936035\n",
            "<tccsnasaurus>\n",
            "loss 13.886422157287598\n",
            "<anyhudt>\n",
            "loss 26.118484497070312\n",
            "<sianospurus>\n",
            "loss 21.89032554626465\n",
            "<ahngisaun>\n",
            "loss 47.643890380859375\n",
            "<aeumaodon>\n",
            "loss 25.068302154541016\n",
            "<aucrrivess>\n",
            "\n",
            "Epoch:18\n",
            "loss 25.32134246826172\n",
            "<llniivosaurus>\n",
            "loss 23.03974151611328\n",
            "<amsaroucopsuen>\n",
            "loss 19.805641174316406\n",
            "<gcbtapturus>\n",
            "loss 27.001266479492188\n",
            "<snaorsturus>\n",
            "loss 15.80753231048584\n",
            "<angaisaurus>\n",
            "loss 15.725276947021484\n",
            "<shbrasaurus>\n",
            "loss 27.258037567138672\n",
            "<wrtarusaurus>\n",
            "\n",
            "Epoch:19\n",
            "loss 25.187416076660156\n",
            "<sngosaohmirs>\n",
            "loss 13.831552505493164\n",
            "<dtahosaurus>\n",
            "loss 20.01199722290039\n",
            "<ataero>\n",
            "loss 12.871066093444824\n",
            "<bttssaurus>\n",
            "loss 17.63759994506836\n",
            "<liusbjraurus>\n",
            "loss 13.088339805603027\n",
            "<taetlcaurus>\n",
            "loss 26.415250778198242\n",
            "<sceoiuaurus>\n",
            "\n",
            "Epoch:20\n",
            "loss 33.73316192626953\n",
            "<rucurnaurus>\n",
            "loss 14.52131462097168\n",
            "<anrcouras>\n",
            "loss 20.00348472595215\n",
            "<lalesaurus>\n",
            "loss 11.0316743850708\n",
            "<wiueshurus>\n",
            "loss 13.801213264465332\n",
            "<ituirttcaurus>\n",
            "loss 27.546630859375\n",
            "<sntalsobaurus>\n",
            "loss 38.19657516479492\n",
            "<tegxrseosaurus>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUQcV0Gx2W_j",
        "colab_type": "text"
      },
      "source": [
        "### Task 2.\n",
        "Перепешите функцию сэмплирования так, чтобы она порождала панграмы (слова, в которых каждая буква встречается только 1 раз)\n",
        "\n",
        "### Task 3.\n",
        "Перепешите функцию сэмплирования так, чтобы было возможно менять температуру сэмплирования\n",
        "\n",
        "### Task 4.\n",
        "Реализуйте beam search для сэмплирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGJwFnOw8jMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# task 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYqhhpp54nSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mask(indices):\n",
        "  mask = []\n",
        "  for i in np.arange(trn_ds.vocab_size):\n",
        "    if i in indices and i != trn_ds.ch_to_idx['u']:\n",
        "      mask.append(0)\n",
        "    else:\n",
        "      mask.append(1)\n",
        "  return np.array(mask)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y3sMwsvkDfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def sample(model):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>'] # индекс конечного символа\n",
        "    with torch.no_grad():\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device) # первый вектор скрытого состояния\n",
        "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<'] # индекс начального символа\n",
        "        x[0, start_char_idx] = 1 # one-hot вектор для начального символа\n",
        "\n",
        "        indices = [start_char_idx]      \n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "            probas = y_softmax_scores.cpu().numpy().ravel()\n",
        "            probas *= get_mask(indices)\n",
        "            sum_proba = sum(probas)\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=[el / sum_proba for el in probas])\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YndwElB76P9I",
        "colab_type": "code",
        "outputId": "d6205c99-211e-4276-f014-39f6b3882761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27, 19, 5, 16, 1, 9, 15, 20, 21, 18, 14, 12, 28]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0OvQMkY7rFg",
        "colab_type": "code",
        "outputId": "0967de30-343e-4cb9-fa9c-a33cf62dab45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print_sample(sample(model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sotaencurux>\n",
            "<tahslcouruk>\n",
            "<tanyoscurul>\n",
            "<soryilcuwuh>\n",
            "<ahteumsurul>\n",
            "<mathigsurup>\n",
            "<crtoelhusux>\n",
            "<sotaencurux>\n",
            "<tahslcouruk>\n",
            "<tanyoscurul>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_CH-7hJ-RpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# task 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4OdZ6A-T-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(model, T):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>'] # индекс конечного символа\n",
        "    with torch.no_grad():\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device) # первый вектор скрытого состояния\n",
        "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<'] # индекс начального символа\n",
        "        x[0, start_char_idx] = 1 # one-hot вектор для начального символа\n",
        "\n",
        "        indices = [start_char_idx]      \n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "      \n",
        "            probas = y_softmax_scores.cpu().numpy().ravel()\n",
        "            probas = probas ** (1/T) # меняем венроятности в соответствии с температурой\n",
        "            sum_proba = sum(probas)\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=[el / sum_proba for el in probas])\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hsrDC_z_Q6-",
        "colab_type": "code",
        "outputId": "8bf5c602-0831-4722-9afd-7074064d0917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print_sample(sample(model, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<naoeulibsar>\n",
            "<qyetusmirus>\n",
            "<vktswakrcmsaukwacsm\n",
            "nguoratalzs>\n",
            "<ctvtlisur>\n",
            "<vktswakrcmsaukwacsm\n",
            "nguoratalzs>\n",
            "<ctvtlisur>\n",
            "<vktswakrcmsaukwacsm\n",
            "nguoratalzs>\n",
            "<ctvtlisur>\n",
            "<vktswakrcmsaukwacsm\n",
            "nguoratalzs>\n",
            "<ctvtlisur>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKLSInzr2W_y",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. Sampling in  RNN: https://nlp.stanford.edu/blog/maximum-likelihood-decoding-with-rnns-the-good-the-bad-and-the-ugly/\n",
        "2. Coursera course (main source): https://github.com/furkanu/deeplearning.ai-pytorch/tree/master/5-%20Sequence%20Models\n",
        "3. Coursera course (main source): https://github.com/Kulbear/deep-learning-coursera/blob/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb\n",
        "4. LSTM: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    }
  ]
}