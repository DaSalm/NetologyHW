{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
    "\n",
    "1. –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞—Ç–∞ —Å–µ—Ç –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ 50:50 70:30 80:20 (—Å –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ–º)\n",
    "2. –û–±—É—á–∞—Ç—å –Ω–∞—à–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç—Ä–µ–π–Ω–µ. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –∏ –∑–∞–º–µ—Ä—è—Ç—å –º–µ—Ç—Ä–∏–∫—É R^2 –∏ –Ω–∞ —Ç—Ä–µ–π–Ω–µ –∏ –Ω–∞ —Ç–µ—Å—Ç–µ\n",
    "3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –º–æ–¥–µ–ª–∏, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: –∞) sales ~ log_tv + radio –±) sales ~ TV + radio –≤) sales ~ TV + radio + newspaper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "\n",
    "def download_file(url, dir_path=\"data\"):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        \n",
    "    file_name = os.path.split(url)[-1]\n",
    "    file_path = os.path.join(dir_path, file_name)\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response, open(file_path, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "        \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nado?\n",
    "from sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df = pd.read_csv('data/Advertising.csv', usecols=[1,2,3,4])\n",
    "adv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ù–∞—á–∞–ª–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 5), (100, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –î–æ–±–∞–≤–∏—Ç—å –∫–æ–ª-–∫—É sq_tv\n",
    "# adv_df['sq_log'] = adv_df.TV.apply(lambda x: math.log(x))\n",
    "adv_df['sq_tv'] = adv_df.TV.apply(lambda x: math.pow(x, 0.4))\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞—Ç–∞ —Å–µ—Ç –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ 50:50 70:30 80:20 (—Å –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ–º\n",
    "y = adv_df['sales'].copy()\n",
    "adv_train, adv_test, y_train, y_test   = train_test_split(adv_df, y, test_size=0.5, random_state=42)\n",
    "adv_train.shape, adv_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sales ~ TV + radio + newspaper + sq_tv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "x_cols = adv_train.columns.drop(\"sales\") \n",
    "y_col = 'sales'\n",
    "\n",
    "x_train = np.array(adv_train[x_cols])\n",
    "x_test = np.array(adv_test[x_cols])\n",
    "y_train = adv_train[y_col]\n",
    "y_test = adv_test[y_col]\n",
    "                  \n",
    "# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ train LinearRegression\n",
    "lm = LinearRegression().fit(\n",
    "    x_train,\n",
    "    y_train\n",
    ")                  \n",
    "                                    \n",
    "# train model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_train_preds = lm.predict(x_train)\n",
    "    \n",
    "# test model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_test_preds = lm.predict(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º RSE –∏ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º ùëÖ2. ùëÖ2‚àà[0,1] - –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞, —á–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –ª—É—á—à–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285475356390764"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 train\n",
    "lm.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9248768400230458"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 test \n",
    "lm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sales ~ sq_tv + radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "x_cols = ['sq_tv','radio']\n",
    "y_col = 'sales'\n",
    "\n",
    "x_train = np.array(adv_train[x_cols])\n",
    "x_test = np.array(adv_test[x_cols])\n",
    "y_train = adv_train[y_col]\n",
    "y_test = adv_test[y_col]\n",
    "                  \n",
    "# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ train LinearRegression\n",
    "lm = LinearRegression().fit(\n",
    "    x_train,\n",
    "    y_train\n",
    ")                  \n",
    "                                    \n",
    "# train model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_train_preds = lm.predict(x_train)\n",
    "    \n",
    "# test model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_test_preds = lm.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9273049082016976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 train\n",
    "lm.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310741259261295"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 test \n",
    "lm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sales ~ TV + radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "x_cols = ['TV','radio']\n",
    "y_col = 'sales'\n",
    "\n",
    "x_train = np.array(adv_train[x_cols])\n",
    "x_test = np.array(adv_test[x_cols])\n",
    "y_train = adv_train[y_col]\n",
    "y_test = adv_test[y_col]\n",
    "                  \n",
    "# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ train LinearRegression\n",
    "lm = LinearRegression().fit(\n",
    "    x_train,\n",
    "    y_train\n",
    ")                  \n",
    "                                    \n",
    "# train model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_train_preds = lm.predict(x_train)\n",
    "    \n",
    "# test model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_test_preds = lm.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020506014720118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 train\n",
    "lm.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8826436017134701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 test \n",
    "lm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sales ~ TV + radio + newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "x_cols = ['TV','radio','newspaper']\n",
    "y_col = 'sales'\n",
    "\n",
    "x_train = np.array(adv_train[x_cols])\n",
    "x_test = np.array(adv_test[x_cols])\n",
    "y_train = adv_train[y_col]\n",
    "y_test = adv_test[y_col]\n",
    "                  \n",
    "# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ train LinearRegression\n",
    "lm = LinearRegression().fit(\n",
    "    x_train,\n",
    "    y_train\n",
    ")                  \n",
    "                                    \n",
    "# train model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_train_preds = lm.predict(x_train)\n",
    "    \n",
    "# test model –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å\n",
    "y_test_preds = lm.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042613648908894"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 train\n",
    "lm.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8721004816045136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞—Ç—å R^2 test \n",
    "lm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è 80:20: –≤–µ–∑–¥–µ test –∑–Ω–∞—á–µ–Ω–∏–µ R^2 –≤—ã—à–µ, —á–µ–º train.\n",
    "–ù–∞–∏–≤—ã—Å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏ R^2 test = 0.942563909350695 –¥–ª—è sales ~ sq_tv + radio. Good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è 70:30: –≤–µ–∑–¥–µ test –∑–Ω–∞—á–µ–Ω–∏–µ R^2 –Ω–∏–∂–µ, —á–µ–º train.\n",
    "–ù–∞–∏–≤—ã—Å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏ R^2 test = 0.9271446043449548 –¥–ª—è sales ~ sq_tv + radio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è 50:50: –≤–µ–∑–¥–µ test –∑–Ω–∞—á–µ–Ω–∏–µ R^2 –Ω–∏–∂–µ, —á–µ–º train, –∫—Ä–æ–º–µ sales ~ sq_tv + radio\n",
    "–ù–∞–∏–≤—ã—Å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏ R^2 test = 0.9310741259261295 –¥–ª—è sales ~ sq_tv + radio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
